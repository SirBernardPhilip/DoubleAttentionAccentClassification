{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import getModelName, getNumberOfSpeakers, Accuracy\n",
    "from data import Dataset\n",
    "from model import SpeakerClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Input params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'train_data_dir': '', \n",
    "'valid_data_dir': '', \n",
    "'train_labels_path': '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/labels.ndx', \n",
    "'valid_clients': '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/clients.ndx', \n",
    "'valid_impostors': '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/impostors.ndx', \n",
    "'max_epochs': 2,\n",
    "    'batch_size': 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute and copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_data_dir': '/scratch/speaker_databases/', 'valid_data_dir': '/scratch/speaker_databases/VoxCeleb-1/wav', 'train_labels_path': 'labels/Vox2.ndx', 'data_mode': 'normal', 'valid_clients': 'labels/clients.ndx', 'valid_impostors': 'labels/impostors.ndx', 'out_dir': './models/model1', 'model_name': 'CNN', 'front_end': 'VGG4L', 'window_size': 3.5, 'randomSlicing': False, 'normalization': 'cmn', 'kernel_size': 1024, 'embedding_size': 400, 'heads_number': 32, 'pooling_method': 'DoubleMHA', 'mask_prob': 0.3, 'scalingFactor': 30.0, 'marginFactor': 0.4, 'annealing': False, 'optimizer': 'Adam', 'learning_rate': 0.0001, 'weight_decay': 0.001, 'batch_size': 64, 'gradientAccumulation': 2, 'max_epochs': 1000000, 'early_stopping': 25, 'print_every': 1000, 'requeue': False, 'validate_every': 10000, 'num_workers': 2}\r\n"
     ]
    }
   ],
   "source": [
    "! python args_input_simulation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'train_data_dir': '', \n",
    "    'valid_data_dir': '', \n",
    "    'train_labels_path': '/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/labels.ndx', \n",
    "    'data_mode': 'normal', \n",
    "    'valid_clients': 'labels/clients.ndx', \n",
    "    'valid_impostors': 'labels/impostors.ndx', \n",
    "    'out_dir': './models/model1', \n",
    "    'model_name': 'CNN', \n",
    "    'front_end': 'VGG4L', \n",
    "    'window_size': 3.5, 'randomSlicing': False, \n",
    "    'normalization': 'cmn', \n",
    "    'kernel_size': 1024, \n",
    "    'embedding_size': 400, \n",
    "    'heads_number': 32, \n",
    "    'pooling_method': 'DoubleMHA', \n",
    "    'mask_prob': 0.3, \n",
    "    'scalingFactor': 30.0, \n",
    "    'marginFactor': 0.4, \n",
    "    'annealing': False, \n",
    "    'optimizer': 'Adam', \n",
    "    'learning_rate': 0.0001, \n",
    "    'weight_decay': 0.001, \n",
    "    'batch_size': 64, \n",
    "    'gradientAccumulation': 2, \n",
    "    'max_epochs': 1000000, \n",
    "    'early_stopping': 25, \n",
    "    'print_every': 1000, \n",
    "    'requeue': False, \n",
    "    'validate_every': 10000, \n",
    "    'num_workers': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Speaker Labels\n",
      "Output folder created at ./models/model1\n",
      "./models/model1/CNN_VGG4L_3.5_128batchSize_0.0001lr_0.001weightDecay_1024kernel_400embSize_30.0s_0.4m_DoubleMHA_32_config.pkl\n"
     ]
    }
   ],
   "source": [
    "params = argparse.Namespace(**params_dict)\n",
    "\n",
    "params.model_name = getModelName(params)\n",
    "params.num_spkrs = getNumberOfSpeakers(params.train_labels_path) \n",
    "\n",
    "print(f\"{params.num_spkrs} Speaker Labels\")\n",
    "\n",
    "if not os.path.exists(params.out_dir):\n",
    "    os.makedirs(params.out_dir)\n",
    "print(f\"Output folder created at {params.out_dir}\")\n",
    "    \n",
    "with open(params.out_dir + '/' + params.model_name + '_config.pkl', 'wb') as handle:\n",
    "    pickle.dump(params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(f\"{params.out_dir + '/' + params.model_name + '_config.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, params, device):\n",
    "\n",
    "        self.params = params\n",
    "        self.device = device\n",
    "        self.__load_network()\n",
    "        self.__load_data()\n",
    "        self.__load_optimizer()\n",
    "        self.__load_criterion()\n",
    "        self.__initialize_training_variables()\n",
    "        \n",
    "        self.params.max_epochs = 2\n",
    "        self.params.batch_size = 32\n",
    "        #self.params.num_workers = 1\n",
    "        \n",
    "    def __load_previous_states(self):\n",
    "\n",
    "        list_files = os.listdir(self.params.out_dir)\n",
    "        list_files = [self.params.out_dir + '/' + f for f in list_files if '.chkpt' in f]\n",
    "        if list_files:\n",
    "            file2load = max(list_files, key=os.path.getctime)\n",
    "            checkpoint = torch.load(file2load, map_location=self.device)\n",
    "            try:\n",
    "                self.net.load_state_dict(checkpoint['model'])\n",
    "            except RuntimeError:\n",
    "                self.net.module.load_state_dict(checkpoint['model'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            self.params = checkpoint['settings']\n",
    "            self.starting_epoch = checkpoint['epoch']+1\n",
    "            self.step = checkpoint['step']\n",
    "            print('Model \"%s\" is Loaded for requeue process' % file2load)\n",
    "        else:\n",
    "            self.step = 0\n",
    "            self.starting_epoch = 1\n",
    "\n",
    "    def __initialize_training_variables(self):\n",
    "\n",
    "        if self.params.requeue:\n",
    "            self.__load_previous_states()\n",
    "        else:\n",
    "            self.step = 0\n",
    "            self.starting_epoch = 0\n",
    "\n",
    "        self.best_EER = 50.0\n",
    "        self.stopping = 0.0\n",
    "\n",
    "\n",
    "    def __load_network(self):\n",
    "\n",
    "        self.net = SpeakerClassifier(self.params, self.device)\n",
    "        self.net.to(self.device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            self.net = nn.DataParallel(self.net)\n",
    "\n",
    "\n",
    "    def __load_data(self):\n",
    "        print('Loading Data and Labels')\n",
    "        with open(self.params.train_labels_path, 'r') as data_labels_file:\n",
    "            train_labels=data_labels_file.readlines()\n",
    "\n",
    "        data_loader_parameters = {'batch_size': self.params.batch_size, 'shuffle': True, 'num_workers': self.params.num_workers}\n",
    "        self.training_generator = DataLoader(Dataset(train_labels, self.params), **data_loader_parameters)\n",
    "\n",
    "\n",
    "    def __load_optimizer(self):\n",
    "        if self.params.optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.net.parameters(), lr=self.params.learning_rate, weight_decay=self.params.weight_decay)\n",
    "        if self.params.optimizer == 'SGD':\n",
    "            self.optimizer = optim.SGD(self.net.parameters(), lr=self.params.learning_rate, weight_decay=self.params.weight_decay)\n",
    "        if self.params.optimizer == 'RMSprop':\n",
    "            self.optimizer = optim.RMSprop(self.net.parameters(), lr=self.params.learning_rate, weight_decay=self.params.weight_decay)\n",
    "\n",
    "    def __update_optimizer(self):\n",
    "\n",
    "        if self.params.optimizer == 'SGD' or self.params.optimizer == 'Adam':\n",
    "            for paramGroup in self.optimizer.param_groups:\n",
    "                paramGroup['lr'] *= 0.5\n",
    "            print('New Learning Rate: {}'.format(paramGroup['lr']))\n",
    "    \n",
    "    def __load_criterion(self):\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def __initialize_batch_variables(self):\n",
    "\n",
    "        self.print_time = time.time()\n",
    "        self.train_loss = 0.0\n",
    "        self.train_accuracy = 0.0\n",
    "        self.train_batch = 0\n",
    "\n",
    "    def __extractInputFromFeature(self, sline):\n",
    "\n",
    "        features1 = normalizeFeatures(featureReader(self.params.valid_data_dir + '/' + sline[0] + '.pickle'), normalization=self.params.normalization)\n",
    "        features2 = normalizeFeatures(featureReader(self.params.valid_data_dir + '/' + sline[1] + '.pickle'), normalization=self.params.normalization)\n",
    "\n",
    "        input1 = torch.FloatTensor(features1).to(self.device)\n",
    "        input2 = torch.FloatTensor(features2).to(self.device)\n",
    "        \n",
    "        return input1.unsqueeze(0), input2.unsqueeze(0)\n",
    "\n",
    "    def __extract_scores(self, trials):\n",
    "\n",
    "        scores = []\n",
    "        for line in trials:\n",
    "            sline = line[:-1].split()\n",
    "\n",
    "            input1, input2 = self.__extractInputFromFeature(sline)\n",
    "\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                emb1, emb2 = self.net.module.getEmbedding(input1), self.net.module.getEmbedding(input2)\n",
    "            else:\n",
    "                emb1, emb2 = self.net.getEmbedding(input1), self.net.getEmbedding(input2)\n",
    "\n",
    "            dist = scoreCosineDistance(emb1, emb2)\n",
    "            scores.append(dist.item())\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def __calculate_EER(self, CL, IM):\n",
    "\n",
    "        thresholds = np.arange(-1,1,0.01)\n",
    "        FRR, FAR = np.zeros(len(thresholds)), np.zeros(len(thresholds))\n",
    "        for idx,th in enumerate(thresholds):\n",
    "            FRR[idx] = Score(CL, th,'FRR')\n",
    "            FAR[idx] = Score(IM, th,'FAR')\n",
    "\n",
    "        EER_Idx = np.argwhere(np.diff(np.sign(FAR - FRR)) != 0).reshape(-1)\n",
    "        if len(EER_Idx)>0:\n",
    "            if len(EER_Idx)>1:\n",
    "                EER_Idx = EER_Idx[0]\n",
    "            EER = round((FAR[int(EER_Idx)] + FRR[int(EER_Idx)])/2,4)\n",
    "        else:\n",
    "            EER = 50.00\n",
    "        return EER\n",
    "\n",
    "    def __getAnnealedFactor(self):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            return self.net.module.predictionLayer.getAnnealedFactor(self.step)\n",
    "        else:\n",
    "            return self.net.predictionLayer.getAnnealedFactor(self.step)\n",
    "\n",
    "    def __validate(self):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_time = time.time()\n",
    "            self.net.eval()\n",
    "            # EER Validation\n",
    "            with open(params.valid_clients,'r') as clients_in, open(params.valid_impostors,'r') as impostors_in:\n",
    "                # score clients\n",
    "                CL = self.__extract_scores(clients_in)\n",
    "                IM = self.__extract_scores(impostors_in)\n",
    "            # Compute EER\n",
    "            EER = self.__calculate_EER(CL, IM)\n",
    "            \n",
    "            annealedFactor = self.__getAnnealedFactor()\n",
    "            print('Annealed Factor is {}.'.format(annealedFactor))\n",
    "            print('--Validation Epoch:{epoch: d}, Updates:{Num_Batch: d}, EER:{eer: 3.3f}, elapse:{elapse: 3.3f} min'.format(epoch=self.epoch, Num_Batch=self.step, eer=EER, elapse=(time.time()-valid_time)/60))\n",
    "            # early stopping and save the best model\n",
    "            if EER < self.best_EER:\n",
    "                self.best_EER = EER\n",
    "                self.stopping = 0\n",
    "                print('We found a better model!')\n",
    "                chkptsave(params, self.net, self.optimizer, self.epoch, self.step)\n",
    "            else:\n",
    "                self.stopping += 1\n",
    "                print('Better Accuracy is: {}. {} epochs of no improvement'.format(self.best_EER, self.stopping))\n",
    "            self.print_time = time.time()\n",
    "            self.net.train()\n",
    "\n",
    "    def __update(self):\n",
    "\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        self.step += 1\n",
    "\n",
    "        if self.step % int(self.params.print_every) == 0:\n",
    "            print('Training Epoch:{epoch: d}, Updates:{Num_Batch: d} -----> xent:{xnet: .3f}, Accuracy:{acc: .2f}, elapse:{elapse: 3.3f} min'.format(epoch=self.epoch, Num_Batch=self.step, xnet=self.train_loss / self.train_batch, acc=self.train_accuracy *100/ self.train_batch, elapse=(time.time()-self.print_time)/60))\n",
    "            self.__initialize_batch_variables()\n",
    "\n",
    "        # validation\n",
    "        if self.step % self.params.validate_every == 0:\n",
    "            self.__validate()\n",
    "\n",
    "    def __updateTrainningVariables(self):\n",
    "\n",
    "        if (self.stopping+1)% 15 ==0:\n",
    "            self.__update_optimizer()\n",
    "\n",
    "    def __randomSlice(self, inputTensor):\n",
    "        index = random.randrange(200,self.params.window_size*100)\n",
    "        return inputTensor[:,:index,:]\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "        print('Start Training')\n",
    "        for self.epoch in range(self.starting_epoch, self.params.max_epochs):  # loop over the dataset multiple times\n",
    "            print(f\"Epoch: {self.epoch}\")\n",
    "            self.net.train()\n",
    "            self.__initialize_batch_variables()\n",
    "            for input, label in self.training_generator:\n",
    "                \n",
    "                #print(self.input)\n",
    "                #print(\"-\"*50)\n",
    "                #print(self.label)\n",
    "                input, label = input.float().to(self.device), label.long().to(self.device)\n",
    "                input = self.__randomSlice(input) if self.params.randomSlicing else input \n",
    "                prediction, AMPrediction  = self.net(input, label=label, step=self.step)\n",
    "                loss = self.criterion(AMPrediction, label)\n",
    "                loss.backward()\n",
    "                self.train_accuracy += Accuracy(prediction, label)\n",
    "                self.train_loss += loss.item()\n",
    "                \n",
    "                self.train_batch += 1\n",
    "                if self.train_batch % self.params.gradientAccumulation == 0:\n",
    "                    self.__update()\n",
    "\n",
    "            if self.stopping > self.params.early_stopping:\n",
    "                print('--Best Model EER%%: %.2f' %(self.best_EER))\n",
    "                break\n",
    "            \n",
    "            self.__updateTrainningVariables()\n",
    "            \n",
    "                #print(f\"label: {self.label}\")\n",
    "                #print(f\"prediction: {prediction}\")\n",
    "                #print(f\"AMPrediction: {AMPrediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Device...\n",
      "device: cuda:0\n",
      "Loading Data and Labels\n",
      "Start Training\n",
      "Epoch: 0\n",
      "Epoch: 1\n",
      "CPU times: user 9.1 s, sys: 3.21 s, total: 12.3 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "    \n",
    "print('Defining Device...')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "\n",
    "trainer = Trainer(params, device)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 17 17:34:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 33%   51C    P2    81W / 250W |  10860MiB / 11019MiB |     51%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      5103      C   ...onda/envs/DASV/bin/python    10857MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/usuaris/veu/federico.costa/datasets/voxceleb2/dev/id09083/2CSYK-bJigI/00002.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/usuaris/veu/federico.costa/datasets/voxceleb2/dev/id09083/2CSYK-bJigI/00002.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     x \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/usuaris/veu/federico.costa/datasets/voxceleb2/dev/id09083/2CSYK-bJigI/00002.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/home/usuaris/veu/federico.costa/datasets/voxceleb2/dev/id09083/2CSYK-bJigI/00002.pickle'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASV",
   "language": "python",
   "name": "dasv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
