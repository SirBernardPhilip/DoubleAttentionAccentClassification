{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train labels generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# were to look for files to make the feature extraction\n",
    "load_path = \"/home/usuaris/veu/federico.costa/datasets/voxceleb2/dev\"\n",
    "\n",
    "# output file path\n",
    "dump_path = \"/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/labels.ndx\"\n",
    "\n",
    "speakers_set = set()\n",
    "speakers_dict = {}\n",
    "for (dir_path, dir_names, file_names) in os.walk(load_path):\n",
    "    speaker_chunk = [chunk for chunk in dir_path.split(\"/\") if chunk.startswith(\"id\")]\n",
    "    \n",
    "    if len(speaker_chunk) > 0: \n",
    "        \n",
    "        speaker_id = speaker_chunk[0]\n",
    "        if speaker_id not in speakers_set:\n",
    "            speakers_dict[speaker_id] = {}\n",
    "            speakers_dict[speaker_id][\"files_paths\"] = set()\n",
    "        speakers_set.add(speaker_id)\n",
    "        \n",
    "        for file_name in file_names:\n",
    "            if file_name.split(\".\")[-1] == \"pickle\":                \n",
    "                \n",
    "                file_path = dir_path + \"/\" + file_name.replace(\".pickle\", \"\")\n",
    "                speakers_dict[speaker_id][\"files_paths\"].add(file_path)\n",
    "        \n",
    "        if len(speaker_chunk) > 1:\n",
    "            warnings.warn(\"Ambiguous directory path!\")\n",
    "\n",
    "speakers_list = list(speakers_set)\n",
    "speakers_list.sort()\n",
    "num_speakers = len(speakers_list)\n",
    "for i, speaker in enumerate(speakers_list):\n",
    "    speakers_dict[speaker][\"speaker_num\"] = i\n",
    "    \n",
    "speakers_dict = {k: v for k, v in sorted(speakers_dict.items(), key=lambda item: item[1][\"speaker_num\"])}\n",
    "    \n",
    "with open(dump_path, 'w') as f:\n",
    "    for key, value in speakers_dict.items():\n",
    "        speaker_num = value[\"speaker_num\"]\n",
    "        for file_path in value[\"files_paths\"]:\n",
    "            line_to_write = f\"{file_path} {speaker_num} -1\"  \n",
    "            f.write(line_to_write)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clients and impostors generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# were to look for files to make the feature extraction\n",
    "load_path = \"/home/usuaris/veu/federico.costa/datasets/voxceleb2/dev\"\n",
    "\n",
    "# output file path\n",
    "impostors_dump_path = \"/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/impostors.ndx\"\n",
    "clients_dump_path = \"/home/usuaris/veu/federico.costa/git_repositories/DoubleAttentionSpeakerVerification/files_directories/labels/clients.ndx\"\n",
    "\n",
    "speakers_set = set()\n",
    "speakers_dict = {}\n",
    "for (dir_path, dir_names, file_names) in os.walk(load_path):\n",
    "    speaker_chunk = [chunk for chunk in dir_path.split(\"/\") if chunk.startswith(\"id\")]\n",
    "    \n",
    "    if len(speaker_chunk) > 0: \n",
    "        \n",
    "        speaker_id = speaker_chunk[0]\n",
    "        if speaker_id not in speakers_set:\n",
    "            speakers_dict[speaker_id] = {}\n",
    "            speakers_dict[speaker_id][\"files_paths\"] = set()\n",
    "        speakers_set.add(speaker_id)\n",
    "        \n",
    "        for file_name in file_names:\n",
    "            if file_name.split(\".\")[-1] == \"pickle\":                \n",
    "                \n",
    "                file_path = dir_path + \"/\" + file_name.replace(\".pickle\", \"\")\n",
    "                speakers_dict[speaker_id][\"files_paths\"].add(file_path)\n",
    "        \n",
    "        if len(speaker_chunk) > 1:\n",
    "            warnings.warn(\"Ambiguous directory path!\")\n",
    "\n",
    "speakers_list = list(speakers_set)\n",
    "speakers_list.sort()\n",
    "num_speakers = len(speakers_list)\n",
    "for i, speaker in enumerate(speakers_list):\n",
    "    speakers_dict[speaker][\"speaker_num\"] = i\n",
    "    \n",
    "speakers_dict = {k: v for k, v in sorted(speakers_dict.items(), key=lambda item: item[1][\"speaker_num\"])}\n",
    "\n",
    "clients_lines_to_write = []\n",
    "impostors_lines_to_write = []\n",
    "\n",
    "distinct_speakers = list(speakers_dict.keys())\n",
    "\n",
    "one_speaker_combinations = [(speaker, speaker) for speaker in distinct_speakers]\n",
    "two_speaker_combinations = list(itertools.combinations(distinct_speakers, 2))  \n",
    "speaker_combinations = one_speaker_combinations + two_speaker_combinations\n",
    "\n",
    "for speaker_1, speaker_2 in speaker_combinations:\n",
    "    \n",
    "    speaker_1_files = speakers_dict[speaker_1][\"files_paths\"]\n",
    "    speaker_2_files = speakers_dict[speaker_2][\"files_paths\"]\n",
    "    \n",
    "    if speaker_1 == speaker_2:\n",
    "        files_combinations = list(itertools.combinations(speaker_1_files, 2))\n",
    "        for file_1, file_2 in files_combinations:\n",
    "            line_to_write = file_1 + \" \" + file_2\n",
    "            clients_lines_to_write.append(line_to_write)\n",
    "    else:\n",
    "        files_combinations = list(itertools.product(speaker_1_files, speaker_2_files))\n",
    "        for file_1, file_2 in files_combinations:\n",
    "            line_to_write = file_1 + \" \" + file_2\n",
    "            impostors_lines_to_write.append(line_to_write)\n",
    "            \n",
    "print(f\"{len(clients_lines_to_write)} lines to write for clients.\")\n",
    "print(f\"{len(impostors_lines_to_write)} lines to write for impostors.\")\n",
    "            \n",
    "with open(clients_dump_path, 'w') as f:\n",
    "    for line_to_write in clients_lines_to_write: \n",
    "        f.write(line_to_write)\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "with open(impostors_dump_path, 'w') as f:\n",
    "    for line_to_write in impostors_lines_to_write: \n",
    "        f.write(line_to_write)\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impostors_dump_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(clients_lines_to_write)} lines to write for clients.\")\n",
    "print(f\"{len(impostors_lines_to_write)} lines to write for impostors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clients_lines_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(impostors_lines_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impostors_lines_to_write[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for k_1, v_1 in speakers_dict.items():\n",
    "    for k_2, v_2 in speakers_dict.items():\n",
    "        if k_1 != k_2:\n",
    "            s = s + len(v_1[\"files_paths\"]) * len(v_2[\"files_paths\"])\n",
    "s/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for k, v in speakers_dict.items():\n",
    "    s = s + math.comb(len(v[\"files_paths\"]), 2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speakers_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for k, v in speakers_dict.items():\n",
    "    s = s + len(v[\"files_paths\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASV",
   "language": "python",
   "name": "dasv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
